#include <iostream>
#include <fstream>
#include <opencv2/videoio.hpp>
#include <stdio.h>
#include <cstdio>
#include <numeric>
#include <opencv2/core.hpp>
#include <opencv2/opencv.hpp>
#include <opencv2/dnn.hpp>
#include <opencv2/highgui.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/dnn/all_layers.hpp>
#include "dataStructures.h"
#include <curl_telegram.h>
A
A
using namespace std;
using namespace cv;
using namespace dnn;
A
void detectYolo(){
    cv::Mat frame;
    cv::VideoCapture cap;
    int deviceID = 0;
    int apiID = cv::CAP_ANY;
    int countStang = 0;
    int countStrat = 0;
A
    cap.open(deviceID + apiID);//, cv::CAP_V4L2);
    //cap.open(0);
A
    if(!cap.isOpened()){
        cerr << "ERROR. Unable to open the camera\n";
    }
    cout << "Start grabbing" << endl
         << "Press any key to terminate" << endl;
    for(;;){
        cap.read(frame);
        cv::Mat img = frame;
        string yoloBasePath = "/home/alexandre-martuscelli/Studies/object_detection/Resources/";
        string yoloClassesFile = yoloBasePath + "classes.txt";
        string yoloModelConfiguration = yoloBasePath + "yolov4-custom.cfg";
        string yoloModelWeights = yoloBasePath + "yolov4-custom_best.weights";
A
        vector<string> classes;
        ifstream ifs(yoloClassesFile.c_str());
        string line;
        while (getline(ifs,line)) classes.push_back(line);
A
        dnn::Net net = dnn::readNetFromDarknet(yoloModelConfiguration, yoloModelWeights);
        net.setPreferableBackend(dnn::DNN_BACKEND_OPENCV);
        net.setPreferableTarget(dnn::DNN_TARGET_CPU);
B
        cv::Mat blob;
        double scaleFactor = 1.0/255.0;
B
        cv::Size size = cv::Size(416,416);
        cv::Scalar mean = cv::Scalar(0,0,0);
        bool swapRB = false;
        bool crop = false;
        auto start = getTickCount();
        cv::dnn::blobFromImage(img, blob, scaleFactor, size, mean, swapRB, crop);
B
        vector<cv::String> names;
        vector<int> outLayers = net.getUnconnectedOutLayers();
        vector<cv::String> layerNames = net.getLayerNames();
B
        names.resize(outLayers.size());
        for(size_t i = 0; i<outLayers.size(); ++i){
            names[i] = layerNames[outLayers[i] - 1];
        }
        vector<cv::Mat> netOutput;
        net.setInput(blob);
        net.forward(netOutput,names);
        auto end = getTickCount();
B
        float confThreshold = 0.8;
        vector<int> classIds;
        vector<float> confidences;
        vector<cv::Rect> boxes;
B
        for (size_t i = 0; i<netOutput.size(); ++i){
            float* data = (float*)netOutput[i].data;
            for(int j = 0; j<netOutput[i].rows; ++j, data+= netOutput[i].cols){
                cv::Mat scores = netOutput[i].row(j).colRange(5, netOutput[i].cols);
                cv::Point classId;
                double confidence;
B
                minMaxLoc(scores,0,&confidence,0,&classId);
                if(confidence > confThreshold){
                    cv::Rect box; int cx, cy;
                    cx = (int)(data[0]*img.cols);
                    cy = (int)(data[1]*img.rows);
                    box.width = (int)(data[2]*img.cols);
                    box.height = (int)(data[3]*img.rows);
                    box.x = cx - box.width/2;
                    box.y = cy - box.height/2;
B
                    boxes.push_back(box);
                    classIds.push_back(classId.x);
                    confidences.push_back((float)confidence);
                }
            }
        }
        float nmsThreshold = 0.2;
        vector<int> indices;
        cv::dnn::NMSBoxes(boxes,confidences,confThreshold,nmsThreshold,indices);
        vector<boundingBox> bBoxes;
        for (auto it = indices.begin(); it != indices.end(); ++it){
            boundingBox bBox;
            bBox.roi = boxes[*it];
            bBox.classID = classIds[*it];
            bBox.confidence = confidences[*it];
            bBox.boxID = (int)bBoxes.size();
B
            bBoxes.push_back(bBox);
        }
B
        cv::Mat visImg = img.clone();
        for (auto it = bBoxes.begin(); it != bBoxes.end(); ++it){
            int top, left, width, height;
            top = (*it).roi.y;
            left = (*it).roi.x;
            width = (*it).roi.width;
            height = (*it).roi.height;
            rectangle(visImg,cv::Point(left,top),cv::Point(left+width,top+height),cv::Scalar(0,0,255),3);
B
            string label = format("%.2f", (*it).confidence);
            label = classes[((*it).classID)] + ":" + label;
            int baseLine;
            cv::Size labelSize = getTextSize(label,cv::FONT_HERSHEY_DUPLEX,0.5,1,&baseLine);
            top = max(top, labelSize.height);
            rectangle(visImg,cv::Point(left,top-round(1.5*labelSize.height)),cv::Point(left + round(1.5*labelSize.width),top),Scalar(0,0,255),cv::FILLED);
            putText(visImg,label,cv::Point(left,top),cv::FONT_HERSHEY_DUPLEX,0.75,cv::Scalar(255,255,255),2);
B
            if (classes[((*it).classID)] == "mustang"){
                countStang++;
                cout << "mustang" << countStang << endl;
                if (countStang >= 10){
                    cv::imwrite(yoloBasePath+"temp/mustang.png", visImg);
                    sendTelegramPhoto("854779848", yoloBasePath+"temp/mustang.png", "We found your Mustang!");
                    cap.release();
                }
            } else if (classes[((*it).classID)] == "stratocaster"){
                countStrat++;
                cout << "stratocaster" << countStrat << endl;
                if (countStrat >= 10){
                    cv::imwrite(yoloBasePath+"temp/stratocaster.png", visImg);
                    sendTelegramPhoto("854779848", yoloBasePath+"temp/stratocaster.png", "We found your Stratocaster!");
                    cap.release();
                }
            }
        }
        string windowName = "Object detection";
        cv::namedWindow(windowName,1);
B
        if(frame.empty()){
            cerr << "ERROR! Blank frame grabbed.\n";
            break;
        }
B
        auto totalTime = (end - start) / getTickFrequency();
B
B
        putText(visImg, "FPS: " + to_string(int(1 / totalTime)), Point(50, 50), cv::FONT_HERSHEY_DUPLEX, 1, Scalar(0, 255, 0), 2, false);
        cv::imshow(windowName,visImg);
        if(cv::waitKey(20)>=0){
            break;
        }
    }
    cap.release();
    destroyAllWindows();
}
B
void detectTensorflow(){
    string file_path = "/home/alexandre-martuscelli/Studies/object_detection/Resources/";
    vector<string> class_names;
    ifstream ifs(string(file_path + "coco.names").c_str());
    string line;
B
    //Load in all the classes from the file
    while (getline(ifs, line))
    {
        cout << line << endl;
        class_names.push_back(line);
    }
B
    string modelConfig = "ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt";
    string modelWeights = "frozen_inference_graph.pb";
    string network = "TensorFlow";
B
    //Read in the neural network from the files
    Net net = readNet(file_path + modelWeights, file_path + modelConfig, network);
    //Open up the webcam
B
    VideoCapture cap(0);//, CAP_V4L2);
B
B
    //Run on either CPU or GPU
    net.setPreferableBackend(DNN_BACKEND_OPENCV);
    net.setPreferableTarget(DNN_TARGET_CPU);
B
B
    //Set a min confidence score for the detections
    float min_confidence_score = 0.75;
B
B
    //Loop running as long as webcam is open and "q" is not pressed
    while (cap.isOpened()) {
B
        //Load in an image
        Mat image;
        bool isSuccess = cap.read(image);
B
        //resize(image, image, Size(416,416));
B
        //Check if image is loaded in correctly
        if (!isSuccess){
            cout << "Could not load the image!" << endl;
            break;
        }
B
B
B
        auto start = getTickCount();
B
        //Create a blob from the image
        Mat blob = blobFromImage(image, 1.0/255, Size(416, 416), Scalar(127.5, 127.5, 127.5), true, true);
B
B
        //Set the blob to be input to the neural network
        net.setInput(blob);
B
        //Forward pass of the blob through the neural network to get the predictions
        Mat output = net.forward();
B
        auto end = getTickCount();
B
B
B
        //Matrix with all the detections
        Mat results(output.size[2], output.size[3], CV_32F, output.ptr<float>());
B
        //Run through all the predictions
        for (int i = 0; i < results.rows; i++){
            int class_id = int(results.at<float>(i, 1));
            float confidence = results.at<float>(i, 2);
B
            //Check if the detection is over the min threshold and then draw bbox
            if (confidence > min_confidence_score){
                int bboxX = int(results.at<float>(i, 3) * image.cols);
                int bboxY = int(results.at<float>(i, 4) * image.rows);
                int bboxWidth = int(results.at<float>(i, 5) * image.cols - bboxX);
                int bboxHeight = int(results.at<float>(i, 6) * image.rows - bboxY);
                rectangle(image, Point(bboxX, bboxY), Point(bboxX + bboxWidth, bboxY + bboxHeight), Scalar(0,0,255), 2);
                string class_name = class_names[class_id-1];
                cout << class_name << endl;
                putText(image, class_name + " " + to_string(int(confidence*100)) + "%", Point(bboxX, bboxY - 10), FONT_HERSHEY_SIMPLEX, 1.5, Scalar(0,255,0), 2);
            }
        }
B
B
        auto totalTime = (end - start) / getTickFrequency();
B
B
        putText(image, "FPS: " + to_string(int(1 / totalTime)), Point(50, 50), FONT_HERSHEY_DUPLEX, 1, Scalar(0, 255, 0), 2, false);
B
        imshow("image", image);
B
B
        int k = waitKey(10);
        if (k == 113){
            break;
        }
    }
B
    cap.release();
    destroyAllWindows();
}
B
int temp()
{
    //detectTensorflow();
    //detectYolo();
    //string chatId = "854779848";
    //string message = "Deu certo saporra!";
    //sendTelegram(message, chatId);
    //sendTelegramPhoto();
    return 0;
}
BBBBBBBBBBBBBBBBAAAAAAAAAAAAAAAAAAAAAAAABBBBBBBBBBBBBBBBBBBBBBBBBBBBAAAAAAAAAAAAAAAAAAAAAAAA